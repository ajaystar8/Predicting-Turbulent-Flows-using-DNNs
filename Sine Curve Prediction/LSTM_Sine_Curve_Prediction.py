# -*- coding: utf-8 -*-
"""PART1: LSTM_SINE_CURVE_THE_IPR_INTERNSHIP_PROGRAM_FINAL_26_OCTOBER

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UnCzWqv6CMHFaTtZNHK3hqkMNsuX5Ark?usp=sharing
"""

'''
Name: Ajay Rajendra Kumar
7th Semester, B.Tech. Computer Science and Engineering
University: Manipal Institute of Technology, Manipal
Date: 23 October, 2023
'''

import numpy as np
import matplotlib.pyplot as plt

X_train = np.arange(0,100,0.5)
y_train = np.sin(X_train)

X_test = np.arange(100,200,0.5)
y_test = np.sin(X_test)

n_features = 1

fig, ax = plt.subplots(1,1,figsize=(15, 4))
ax.plot(X_train, y_train, lw = 3, label = 'train data')
ax.plot(X_test, y_test, lw = 3, label = 'test data')
ax.legend(loc = 'lower left')
plt.show()

import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
import torch.optim as optim

train_series = torch.from_numpy(y_train)
test_series = torch.from_numpy(y_test)

len(train_series)

look_back = 20

train_dataset = []
train_labels = []

for i in range(len(train_series)-look_back):
  train_dataset.append(train_series[i:i+look_back])
  train_labels.append(train_series[i+look_back])

train_dataset = torch.stack(train_dataset).unsqueeze(0)
train_labels = torch.stack(train_labels).unsqueeze(0).unsqueeze(2)

print(train_dataset.shape)

print(train_labels.shape)

class LSTM(nn.Module):
  def __init__(self, n_neurons, input_shape):
    super(LSTM, self).__init__()
    self.lstm = nn.LSTM(input_size = input_shape, hidden_size = n_neurons, batch_first = True)
    self.fc = nn.Linear(n_neurons, 1)

  def forward(self, x):
    out, _ = self.lstm(x)
    out = self.fc(out)
    return out

n_neurons = 4

model = LSTM(n_neurons = n_neurons, input_shape = look_back).double()
loss_function = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr = 0.01)

for epoch in range(100):
  model.zero_grad()
  predictions = model(train_dataset)
  loss = loss_function(predictions, train_labels)
  loss.backward()
  optimizer.step()

  if epoch % 5 == 0:
    print(f"epoch: {epoch: 4} loss: {loss.item():10.8f}")

test_dataset = [test_series[i:i+look_back] for i in range(len(train_series)-look_back)]
test_dataset = torch.stack(test_dataset).unsqueeze(0)

with torch.no_grad():
    test_predictions = model(test_dataset).squeeze()

test_predictions.shape

x = np.linspace(110, 200, 180)
fig, ax = plt.subplots(1, 1, figsize=(15, 5))
ax.plot(X_train,y_train, lw=2, label='train data')
ax.plot(X_test,y_test, lw=3, c='y', label='test data')
ax.plot(x,test_predictions, lw=3, c='r',linestyle = ':', label='predictions')
ax.legend(loc="lower left")
plt.show();

